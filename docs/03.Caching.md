## Caching
- 로드밸런싱과 캐싱 관계
    - 로드밸런싱은 지속적으로 증가하는 서버 수에 걸쳐 수평적으로 확장하는데 도움이 된다.
    - 캐싱을 사용하면 이미 보유한 리소스를 훨씬 더 효과적으로 사용할 수 있다.
- 캐시는 참조 원칙의 지역성을 활용한다. (advantage of the locality of reference principle)
    - 최근 요청된 데이터는 다시 요청될 가능성이 높다.
    - 하드웨어, 운영체제, 웹 브라우저, 웹 응용 프로그램 등 거의 모든 컴퓨팅 계층에서 사용된다.

- 캐시는 `단기 메모리`와 비슷하다.
    - 공간이 제약되어 있지만, 일반적으로 원래 데이터 소스보다 빠르며 가장 최근에 엑세스 한 항목을 포함한다.

- `캐시`는 아키텍처의 모든 레벨에 존재할 수 있다.
    - 종종 다운 스트림 수준에 부담을 주지 않고 데이터를 빠르게 반환하기 위해 구현된 프론트 엔드에 가장 가까운 레벨에서 발견된다.

### Application Server Cache
- 요청 계층 노드(Application Server)에 캐시를 배치하면 응답 데이터(response)를 로컬 스토리지(local storage)에 저장 할수 있다.
    - 서비스에 대한 요청이 있을때 노드는 로컬 캐시 데이터가 있는 경우 신속하게 반환한다.
    - 캐시에 없으면 요청 노드가 디스크에서 데이터를 조회(query)한다.
    - 하나의 요청 계층 노드에 있는 캐시는 메모리(매우 빠름)와 노드의 로컬 디스크(네트워크 스토리지로 이동하는 것보다 빠름) 모두에 위치 할 수 있다.

- 여러 노드로 확장하는 경우
    - 요청 계층이 여러 노드로 확장되는 경우에도 각 노드가 자체 캐시를 호스팅 할 수 있다.
    - 하지만 로드밸런서가 노드에 요청을 임의로 분산하면 동일한 요청이 다른 노드로 이동하므로 캐시 누락이 증가한다.
    - 이러한 장애를 극복하기 위한 두 가지 선택 사항은 글로벌 캐시와 분산 캐시이다.

### Content Distribution Network(CDN)
- CDN은 많은 양의 정적 미디어를 제공하는 사이트에서 사용되는 일종의 캐시이다.
- 일반적인 CDN 설정에서 요청은 먼저 CDN에 정적 미디어를 요청한다.
- CDN은 해당 컨텐츠를 로컬에서 사용할 수 있는 경우 제공한다.
- 사용할 수없는 경우 CDN은 백엔드 서버에 파일을 쿼리하고 로컬로 캐시 한 다음 요청하는 사용자에게 제공합니다.

- 구축하려는 시스템이 자체 CDN을 가질만큼 충분히 크지 않은 경우 
    - Nginx와 같은 경량 HTTP 서버를 사용하여 별도의 하위 도메인에서 정적 미디어를 제공함으로써 향후 전환을 쉽게 할 수 있다.
    - 나중에 CDN으로 DNS를 이관(cut-over)한다.

### Cache Invalidation
- 캐싱을 Database처럼 일관되게 유지하기 위해서는 관리가 필요하다.
    - 데이터가 데이터베이스에서 수정되면 캐시가 뮤효화되어야 한다. 그렇지 않으면 일관성없는 애플리케이션 동작이 발생할 수 있다.

- 캐시 무효화 세 가지 주요 체계
    1. `Write-through cache`
        - 이 방식에서는 데이터가 캐시와 해당 데이터베이스에 동시에 기록된다. 
        - 캐시된 데이터는 빠른 검색을 가능하게하며 동일한 데이터가 영구 저장소에 기록되기 때문에 캐시와 저장소 간에 완전한 데이터 일관성을 갖게된다. 
        - 또한이 체계는 충돌, 정전 또는 기타 시스템 중단시 손실되는 것이 없도록한다.
          
        - 데이터 손실 위험을 최소화하지만 
          모든 쓰기 작업은 클라이언트에 성공하기 전에 두 번 수행해야하므로 `쓰기 작업에 대한 지연 시간이 길다`는 단점이 있다.
         
    2. `Write-around cache`
        - 이 방식은 `Write-through cache`와 유사하지만 데이터는 `캐시를 우회(bypassing the cache)`하여 영구 저장소에 직접 기록된다.
        - 이 경우 나중에 `다시 읽지 않는 쓰기 작업`으로 가득 찬 캐시를 줄일 수 있다.
        - 하지만 최근에 쓴 데이터에 대한 읽기 요청이 `캐시 미스(cache miss)`를 생성하고 
          느린 백엔드 스토리지 및 경험에서 읽어야 한다는 것과 높은 지연율이라는 단점이 있다.

    3. `Write-back cache`
        - 이 방식에서는 데이터가 캐시에만 기록되어 완료되고 클라이언트에서 즉시 확인된다.
        - 영구 저장소에 대한 쓰기는 지정된 간격 후에 또는 특정 조건에서 수행된다.
        - 이로 인해 쓰기 집약적인 애플리케이션의 경우 지연 시간이 짧고 처리량이 높아진다.
        - 그러나 이 속도는 기록된 데이터의 유일한 사본이 캐시에 있기 때문에 충돌 또는 기타 불리한 이벤트가 발생할 경우 데이터 손실 위험이 따른다.

### Cache eviction policies
- 캐시 제거 정책의 일부
    1. FIFO (선입 선출) : 캐시는 이전에 액세스 한 빈도 또는 횟수에 관계없이 먼저 액세스 한 첫 번째 블록을 제거한다.
    2. LIFO (Last In First Out) : 캐시는 이전에 액세스 한 빈도 또는 횟수에 관계없이 가장 최근에 액세스 한 블록을 먼저 제거한다.
    3. 가장 최근에 사용한 항목 (LRU) : 가장 최근에 사용한 항목을 먼저 버린다.
    4. 가장 최근에 사용한 항목 (MRU) : LRU와 달리 가장 최근에 사용한 항목을 먼저 버린다.
    5. LFU (Least Frequently Used) : 항목이 필요한 빈도를 계산합니다. 가장 자주 사용되지 않는 항목이 먼저 폐기된다.
    6. 무작위 교체 (RR) : 후보 항목을 무작위로 선택하고 필요할 때 공간을 확보하기 위해 버린다.
    
### 참고
- [캐시](https://en.wikipedia.org/wiki/Cache_(computing))
- [시스템 설계 소개](https://lethain.com/introduction-to-architecting-systems-for-scale/)
